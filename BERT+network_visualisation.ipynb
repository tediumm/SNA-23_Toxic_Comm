{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dee4d8da",
   "metadata": {},
   "source": [
    "## Importing data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dee0250a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kripa\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\kripa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\kripa\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_nostop</th>\n",
       "      <th>comment_text_stem</th>\n",
       "      <th>comment_text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>003b9f448ee4a29d</td>\n",
       "      <td>\"\\n\\nThanks. I can see that violating clearly ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nthanks i can see that violating clearly st...</td>\n",
       "      <td>thanks see violating clearly stated wikipedia ...</td>\n",
       "      <td>thank see violat clear state wikipedia polici ...</td>\n",
       "      <td>thank see violat clear state wikipedia polici ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00078f8ce7eb276d</td>\n",
       "      <td>\"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\njuelz santanas age\\n\\nin  juelz santana wa...</td>\n",
       "      <td>juelz santanas age juelz santana years old cam...</td>\n",
       "      <td>juelz santana age juelz santana year old came ...</td>\n",
       "      <td>juelz santana age juelz santana year old came ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0011cc71398479c4</td>\n",
       "      <td>How could I post before the block expires?  Th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how could i post before the block expires  the...</td>\n",
       "      <td>could post block expires funny thing think im ...</td>\n",
       "      <td>could post block expir funni thing think im un...</td>\n",
       "      <td>could post block expir funni thing think im un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0061b075244dd234</td>\n",
       "      <td>Once again, I responded to MileMoney's reasoni...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>once again i responded to milemoneys reasoning...</td>\n",
       "      <td>responded milemoneys reasoning edit gave reaso...</td>\n",
       "      <td>respond milemoney reason edit gave reason edit...</td>\n",
       "      <td>respond milemoney reason edit gave reason edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0052a7e684beeb1a</td>\n",
       "      <td>\". (On Dec 14, 2006, a NIST scientist said \"\"....</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>on dec   a nist scientist said the collapse o...</td>\n",
       "      <td>dec nist scientist said collapse towers magnit...</td>\n",
       "      <td>dec nist scientist said collaps tower magnitud...</td>\n",
       "      <td>dec nist scientist said collaps tower magnitud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>002264ea4d5f2887</td>\n",
       "      <td>Why can't you believe how fat Artie is? Did yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>why cant you believe how fat artie is did you ...</td>\n",
       "      <td>cant believe fat artie see recent appearence t...</td>\n",
       "      <td>cant believ fat arti see recent appear tonight...</td>\n",
       "      <td>cant believ fat arti see recent appear tonight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>006a263a08b593c5</td>\n",
       "      <td>Note that the Sandbox is the right place to ex...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>note that the sandbox is the right place to ex...</td>\n",
       "      <td>note sandbox right place experment thanks</td>\n",
       "      <td>note sandbox right place exper thank</td>\n",
       "      <td>note sandbox right place exper thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0053978373606ba4</td>\n",
       "      <td>TCM \\n\\nI can find no evidence that acupressur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tcm \\n\\ni can find no evidence that acupressur...</td>\n",
       "      <td>tcm find evidence acupressure tcm rather deriv...</td>\n",
       "      <td>tcm find evid acupressur tcm rather deriv tcm ...</td>\n",
       "      <td>tcm find evid acupressur tcm rather deriv tcm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>000897889268bc93</td>\n",
       "      <td>REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "      <td>redirect talkvoydan pop georgiev chernodrinski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>002b90cc8a94c76b</td>\n",
       "      <td>They are NOT original research, they are point...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>they are not original research they are pointe...</td>\n",
       "      <td>original research pointed episodes</td>\n",
       "      <td>origin research point episod</td>\n",
       "      <td>origin research point episod</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>160 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                       comment_text  \\\n",
       "95   003b9f448ee4a29d  \"\\n\\nThanks. I can see that violating clearly ...   \n",
       "15   00078f8ce7eb276d  \"\\n\\nJuelz Santanas Age\\n\\nIn 2002, Juelz Sant...   \n",
       "30   0011cc71398479c4  How could I post before the block expires?  Th...   \n",
       "158  0061b075244dd234  Once again, I responded to MileMoney's reasoni...   \n",
       "128  0052a7e684beeb1a  \". (On Dec 14, 2006, a NIST scientist said \"\"....   \n",
       "..                ...                                                ...   \n",
       "59   002264ea4d5f2887  Why can't you believe how fat Artie is? Did yo...   \n",
       "171  006a263a08b593c5  Note that the Sandbox is the right place to ex...   \n",
       "131  0053978373606ba4  TCM \\n\\nI can find no evidence that acupressur...   \n",
       "17   000897889268bc93   REDIRECT Talk:Voydan Pop Georgiev- Chernodrinski   \n",
       "72   002b90cc8a94c76b  They are NOT original research, they are point...   \n",
       "\n",
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "95       0             0        0       0       0              0   \n",
       "15       0             0        0       0       0              0   \n",
       "30       0             0        0       0       0              0   \n",
       "158      0             0        0       0       0              0   \n",
       "128      0             0        0       0       0              0   \n",
       "..     ...           ...      ...     ...     ...            ...   \n",
       "59       1             0        0       0       0              0   \n",
       "171      0             0        0       0       0              0   \n",
       "131      0             0        0       0       0              0   \n",
       "17       0             0        0       0       0              0   \n",
       "72       0             0        0       0       0              0   \n",
       "\n",
       "                                    comment_text_clean  \\\n",
       "95   \\n\\nthanks i can see that violating clearly st...   \n",
       "15   \\n\\njuelz santanas age\\n\\nin  juelz santana wa...   \n",
       "30   how could i post before the block expires  the...   \n",
       "158  once again i responded to milemoneys reasoning...   \n",
       "128   on dec   a nist scientist said the collapse o...   \n",
       "..                                                 ...   \n",
       "59   why cant you believe how fat artie is did you ...   \n",
       "171  note that the sandbox is the right place to ex...   \n",
       "131  tcm \\n\\ni can find no evidence that acupressur...   \n",
       "17      redirect talkvoydan pop georgiev chernodrinski   \n",
       "72   they are not original research they are pointe...   \n",
       "\n",
       "                                   comment_text_nostop  \\\n",
       "95   thanks see violating clearly stated wikipedia ...   \n",
       "15   juelz santanas age juelz santana years old cam...   \n",
       "30   could post block expires funny thing think im ...   \n",
       "158  responded milemoneys reasoning edit gave reaso...   \n",
       "128  dec nist scientist said collapse towers magnit...   \n",
       "..                                                 ...   \n",
       "59   cant believe fat artie see recent appearence t...   \n",
       "171          note sandbox right place experment thanks   \n",
       "131  tcm find evidence acupressure tcm rather deriv...   \n",
       "17      redirect talkvoydan pop georgiev chernodrinski   \n",
       "72                  original research pointed episodes   \n",
       "\n",
       "                                     comment_text_stem  \\\n",
       "95   thank see violat clear state wikipedia polici ...   \n",
       "15   juelz santana age juelz santana year old came ...   \n",
       "30   could post block expir funni thing think im un...   \n",
       "158  respond milemoney reason edit gave reason edit...   \n",
       "128  dec nist scientist said collaps tower magnitud...   \n",
       "..                                                 ...   \n",
       "59   cant believ fat arti see recent appear tonight...   \n",
       "171               note sandbox right place exper thank   \n",
       "131  tcm find evid acupressur tcm rather deriv tcm ...   \n",
       "17      redirect talkvoydan pop georgiev chernodrinski   \n",
       "72                        origin research point episod   \n",
       "\n",
       "                                     comment_text_lemm  \n",
       "95   thank see violat clear state wikipedia polici ...  \n",
       "15   juelz santana age juelz santana year old came ...  \n",
       "30   could post block expir funni thing think im un...  \n",
       "158  respond milemoney reason edit gave reason edit...  \n",
       "128  dec nist scientist said collaps tower magnitud...  \n",
       "..                                                 ...  \n",
       "59   cant believ fat arti see recent appear tonight...  \n",
       "171               note sandbox right place exper thank  \n",
       "131  tcm find evid acupressur tcm rather deriv tcm ...  \n",
       "17      redirect talkvoydan pop georgiev chernodrinski  \n",
       "72                        origin research point episod  \n",
       "\n",
       "[160 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>comment_text_nostop</th>\n",
       "      <th>comment_text_stem</th>\n",
       "      <th>comment_text_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "      <td>daww match background colour im seem stuck tha...</td>\n",
       "      <td>daww match background colour im seem stuck tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00070ef96486d6f9</td>\n",
       "      <td>Oh, and the girl above started her arguments w...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh and the girl above started her arguments wi...</td>\n",
       "      <td>oh girl started arguments stuck nose doesnt be...</td>\n",
       "      <td>oh girl start argument stuck nose doesnt belon...</td>\n",
       "      <td>oh girl start argument stuck nose doesnt belon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>000b08c464718505</td>\n",
       "      <td>\"\\n\\n Regarding your recent edits \\n\\nOnce aga...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n regarding your recent edits \\n\\nonce agai...</td>\n",
       "      <td>regarding recent edits please read wpfilmplot ...</td>\n",
       "      <td>regard recent edit pleas read wpfilmplot edit ...</td>\n",
       "      <td>regard recent edit plea read wpfilmplot edit f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>000bfd0867774845</td>\n",
       "      <td>\"\\nGood to know. About me, yeah, I'm studying ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\ngood to know about me yeah im studying nowde...</td>\n",
       "      <td>good know yeah im studying nowdeepu</td>\n",
       "      <td>good know yeah im studi nowdeepu</td>\n",
       "      <td>good know yeah im studi nowdeepu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0015f4aa35ebe9b5</td>\n",
       "      <td>pretty much everyone from warren county/surrou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pretty much everyone from warren countysurroun...</td>\n",
       "      <td>pretty much everyone warren countysurrounding ...</td>\n",
       "      <td>pretti much everyon warren countysurround regi...</td>\n",
       "      <td>pretti much everyon warren countysurround regi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>001cadfd324f8087</td>\n",
       "      <td>\"\\nAs for your claims of \"\"stalking\"\", that is...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nas for your claims of stalking that is absol...</td>\n",
       "      <td>claims stalking absolute rubbish serves aggrav...</td>\n",
       "      <td>claim stalk absolut rubbish serv aggrav situat...</td>\n",
       "      <td>claim stalk absolut rubbish serv aggrav situat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>001d8e7be417776a</td>\n",
       "      <td>\"\\n\\nBI, you said you wanted to talk\\n\\nAt the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nbi you said you wanted to talk\\n\\nat the b...</td>\n",
       "      <td>bi said wanted talk bottom lead section writte...</td>\n",
       "      <td>bi said want talk bottom lead section written ...</td>\n",
       "      <td>bi said want talk bottom lead section written ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>001e89eb3f0b0915</td>\n",
       "      <td>Are you threatening me for disputing neutralit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>are you threatening me for disputing neutralit...</td>\n",
       "      <td>threatening disputing neutrality know country ...</td>\n",
       "      <td>threaten disput neutral know countri quit comm...</td>\n",
       "      <td>threaten disput neutral know countri quit comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>001ffdcc3e7fb49c</td>\n",
       "      <td>Awesome! Then I'll simply disregard your notic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>awesome then ill simply disregard your notice ...</td>\n",
       "      <td>awesome ill simply disregard notice thanks</td>\n",
       "      <td>awesom ill simpli disregard notic thank</td>\n",
       "      <td>awesom ill simpli disregard notic thank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>00218d74784ce50b</td>\n",
       "      <td>\"\\n\\n GA Review II \\n\\nI'm sorry to say this, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n ga review ii \\n\\nim sorry to say this but...</td>\n",
       "      <td>ga review ii im sorry say fail articles gan se...</td>\n",
       "      <td>ga review ii im sorri say fail articl gan seve...</td>\n",
       "      <td>ga review ii im sorri say fail articl gan seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0021fe88bc4da3e6</td>\n",
       "      <td>My Band Page's deletion. You thought I was gon...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>my band pages deletion you thought i was gone ...</td>\n",
       "      <td>band pages deletion thought gone deleting comm...</td>\n",
       "      <td>band page delet thought gone delet comment pos...</td>\n",
       "      <td>band page delet thought gone delet comment pos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>002746baedcdff10</td>\n",
       "      <td>\"\\n\\n\"\"Christian arabs\"\"\\nHi. Could you please...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nchristian arabs\\nhi could you please stop ...</td>\n",
       "      <td>christian arabs hi could please stop enforcing...</td>\n",
       "      <td>christian arab hi could pleas stop enforc cate...</td>\n",
       "      <td>christian arab hi could plea stop enforc categ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>002a6beca33307b3</td>\n",
       "      <td>I would appreciate an apology from both of you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i would appreciate an apology from both of you...</td>\n",
       "      <td>would appreciate apology see unlikely please d...</td>\n",
       "      <td>would appreci apolog see unlik pleas dont wast...</td>\n",
       "      <td>would appreci apolog see unlik plea dont wast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>002d6c9d9f85e81f</td>\n",
       "      <td>\"\\nWhile the magazine's masthead says \"\"TIME\"\"...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nwhile the magazines masthead says time the c...</td>\n",
       "      <td>magazines masthead says time corporate name ti...</td>\n",
       "      <td>magazin masthead say time corpor name time inc...</td>\n",
       "      <td>magazin masthead say time corpor name time inc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0036e50f42d0b679</td>\n",
       "      <td>Oh, it's me vandalising?xD See here. Greetings,</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>oh its me vandalisingxd see here greetings</td>\n",
       "      <td>oh vandalisingxd see greetings</td>\n",
       "      <td>oh vandalisingxd see greet</td>\n",
       "      <td>oh vandalisingxd see greet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0037e59caead9dab</td>\n",
       "      <td>Website \\n\\nHey all,\\nI was thinking of gettin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>website \\n\\nhey all\\ni was thinking of getting...</td>\n",
       "      <td>website hey thinking getting website display p...</td>\n",
       "      <td>websit hey think get websit display pictur che...</td>\n",
       "      <td>websit hey think get websit display pictur che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>003910ffa2f50517</td>\n",
       "      <td>\"\\nAlmost got me too; I had to look it up to s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\nalmost got me too i had to look it up to see...</td>\n",
       "      <td>almost got look see real talk</td>\n",
       "      <td>almost got look see real talk</td>\n",
       "      <td>almost got look see real talk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>003dbd1b9b354c1f</td>\n",
       "      <td>You can do all you're doing right now but if y...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>you can do all youre doing right now but if yo...</td>\n",
       "      <td>youre right get username youll able impact im ...</td>\n",
       "      <td>your right get usernam youll abl impact im say...</td>\n",
       "      <td>your right get usernam youll abl impact im say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0040017ef6277334</td>\n",
       "      <td>i can't believe no one has already put up this...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i cant believe no one has already put up this ...</td>\n",
       "      <td>cant believe one already put page dilberts des...</td>\n",
       "      <td>cant believ one alreadi put page dilbert deskt...</td>\n",
       "      <td>cant believ one alreadi put page dilbert deskt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>004176f28a17bf45</td>\n",
       "      <td>\"\\n\\nWell, after I asked you to provide the di...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nwell after i asked you to provide the diff...</td>\n",
       "      <td>well asked provide diffs within one hour next ...</td>\n",
       "      <td>well ask provid diff within one hour next edit...</td>\n",
       "      <td>well ask provid diff within one hour next edit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>00480b6e1f19601b</td>\n",
       "      <td>I tend to think that when the list is longer t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>i tend to think that when the list is longer t...</td>\n",
       "      <td>tend think list longer rest article theres pro...</td>\n",
       "      <td>tend think list longer rest articl there probl...</td>\n",
       "      <td>tend think list longer rest articl there probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0048de0c9422f64f</td>\n",
       "      <td>\"\\n\\n What's up with this? \\n\"\"If you are a re...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n whats up with this \\nif you are a religio...</td>\n",
       "      <td>whats religiously politically motivated push i...</td>\n",
       "      <td>what religi polit motiv push issu pleas refrai...</td>\n",
       "      <td>what religi polit motiv push issu plea refrain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>004d07d94cb92e35</td>\n",
       "      <td>Bigfoot Reference \\n\\nThe magazine is better k...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>bigfoot reference \\n\\nthe magazine is better k...</td>\n",
       "      <td>bigfoot reference magazine better known engine...</td>\n",
       "      <td>bigfoot refer magazin better known engin mine ...</td>\n",
       "      <td>bigfoot refer magazin better known engin mine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>004f6dbe69f3545d</td>\n",
       "      <td>Conformity as healthy \\n\\nI may have missed it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>conformity as healthy \\n\\ni may have missed it...</td>\n",
       "      <td>conformity healthy may missed article seem add...</td>\n",
       "      <td>conform healthi may miss articl seem address c...</td>\n",
       "      <td>conform healthi may miss articl seem address c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>005306a4c109dab3</td>\n",
       "      <td>The statement drawn from Watchtower literature...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>the statement drawn from watchtower literature...</td>\n",
       "      <td>statement drawn watchtower literature honestly...</td>\n",
       "      <td>statement drawn watchtow literatur honest clan...</td>\n",
       "      <td>statement drawn watchtow literatur honest clan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>00537730daf8c5f1</td>\n",
       "      <td>Sorry about that.  I had checked, but had only...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sorry about that  i had checked but had only c...</td>\n",
       "      <td>sorry checked come dulas bay somehow missed du...</td>\n",
       "      <td>sorri check come dula bay somehow miss dula di...</td>\n",
       "      <td>sorri check come dula bay somehow miss dula di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>00548f16a392d8ed</td>\n",
       "      <td>Meivazhi\\nI've had a go at restarting the Meiv...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>meivazhi\\nive had a go at restarting the meiva...</td>\n",
       "      <td>meivazhi ive go restarting meivazhi article st...</td>\n",
       "      <td>meivazhi ive go restart meivazhi articl style ...</td>\n",
       "      <td>meivazhi ive go restart meivazhi articl style ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>005eb6d31a8d821e</td>\n",
       "      <td>From what I've seen with editors other than Er...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>from what ive seen with editors other than eri...</td>\n",
       "      <td>ive seen editors eric elephant room issue bait...</td>\n",
       "      <td>ive seen editor eric eleph room issu baitingpo...</td>\n",
       "      <td>ive seen editor eric eleph room issu baitingpo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>005f59485fcddeb0</td>\n",
       "      <td>\"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\nsorry puck but no one ever said dick was n...</td>\n",
       "      <td>sorry puck one ever said dick number one clear...</td>\n",
       "      <td>sorri puck one ever said dick number one clear...</td>\n",
       "      <td>sorri puck one ever said dick number one clear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>006120d209a4a46c</td>\n",
       "      <td>\"\\n\\n  \\n\\nYour request to be unblocked has be...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n  \\n\\nyour request to be unblocked has bee...</td>\n",
       "      <td>request unblocked granted following reasons al...</td>\n",
       "      <td>request unblock grant follow reason allow user...</td>\n",
       "      <td>request unblock grant follow reason allow user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0063a8786a7034fc</td>\n",
       "      <td>\"== Attributing and classifying of personaliti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>attributing and classifying of personalities ...</td>\n",
       "      <td>attributing classifying personalities invitati...</td>\n",
       "      <td>attribut classifi person invit input cultur li...</td>\n",
       "      <td>attribut classifi person invit input cultur li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>006854d70298693e</td>\n",
       "      <td>Hi \\n\\nHi, good day.\\n\\nMy deepest apologies t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hi \\n\\nhi good day\\n\\nmy deepest apologies tha...</td>\n",
       "      <td>hi hi good day deepest apologies made change m...</td>\n",
       "      <td>hi hi good day deepest apolog made chang made ...</td>\n",
       "      <td>hi hi good day deepest apolog made chang made ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>006b888560bcdfcd</td>\n",
       "      <td>\"know the sex of the foetus\"\"\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>know the sex of the foetus</td>\n",
       "      <td>know sex foetus</td>\n",
       "      <td>know sex foetus</td>\n",
       "      <td>know sex foetus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>006d11791d76b9f3</td>\n",
       "      <td>REPLY ABOVE:\\nThat was me, loser. The UN defin...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>reply above\\nthat was me loser the un defines ...</td>\n",
       "      <td>reply loser un defines vietnam part southeast ...</td>\n",
       "      <td>repli loser un defin vietnam part southeast as...</td>\n",
       "      <td>repli loser un defin vietnam part southeast as...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>006f2c1459f3b6b1</td>\n",
       "      <td>\"== new ==\\n\\n{{userbox \\n TABTAB| id =  \\n TA...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>new \\n\\nuserbox \\n tabtab id   \\n tabtab idc ...</td>\n",
       "      <td>new userbox tabtab id tabtab idc white tabtab ...</td>\n",
       "      <td>new userbox tabtab id tabtab idc white tabtab ...</td>\n",
       "      <td>new userbox tabtab id tabtab idc white tabtab ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0073059e6433db47</td>\n",
       "      <td>George W. Bush approval rating graph \\n\\nhttp:...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>george w bush approval rating graph \\n\\nhttpup...</td>\n",
       "      <td>george w bush approval rating graph httpupload...</td>\n",
       "      <td>georg w bush approv rate graph httpuploadwikim...</td>\n",
       "      <td>georg w bush approv rate graph httpuploadwikim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>007571394afafcb5</td>\n",
       "      <td>\"\\n, editors don't care about your \"\"explanati...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>\\n editors dont care about your explanations i...</td>\n",
       "      <td>editors dont care explanations theyre accompan...</td>\n",
       "      <td>editor dont care explan theyr accompani reliab...</td>\n",
       "      <td>editor dont care explan theyr accompani reliab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>007810bde7d6ebd4</td>\n",
       "      <td>About Mitch moved to Yggdrasill \\n\\nI have no ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>about mitch moved to yggdrasill \\n\\ni have no ...</td>\n",
       "      <td>mitch moved yggdrasill idea wasnt</td>\n",
       "      <td>mitch move yggdrasil idea wasnt</td>\n",
       "      <td>mitch move yggdrasil idea wasnt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>007bc29766a43e3c</td>\n",
       "      <td>Review Request \\n\\nHi,\\n\\nI'd like to request ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>review request \\n\\nhi\\n\\nid like to request kl...</td>\n",
       "      <td>review request hi id like request klm gaclass ...</td>\n",
       "      <td>review request hi id like request klm gaclass ...</td>\n",
       "      <td>review request hi id like request klm gaclass ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>007ecbb379c4a861</td>\n",
       "      <td>Al Messier \\nThis article was a non-notable bi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>al messier \\nthis article was a nonnotable bio...</td>\n",
       "      <td>al messier article nonnotable biography accord...</td>\n",
       "      <td>al messier articl nonnot biographi accord crit...</td>\n",
       "      <td>al messier articl nonnot biographi accord crit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                       comment_text  \\\n",
       "1    000103f0d9cfb60f  D'aww! He matches this background colour I'm s...   \n",
       "14   00070ef96486d6f9  Oh, and the girl above started her arguments w...   \n",
       "20   000b08c464718505  \"\\n\\n Regarding your recent edits \\n\\nOnce aga...   \n",
       "21   000bfd0867774845  \"\\nGood to know. About me, yeah, I'm studying ...   \n",
       "37   0015f4aa35ebe9b5  pretty much everyone from warren county/surrou...   \n",
       "48   001cadfd324f8087  \"\\nAs for your claims of \"\"stalking\"\", that is...   \n",
       "50   001d8e7be417776a  \"\\n\\nBI, you said you wanted to talk\\n\\nAt the...   \n",
       "52   001e89eb3f0b0915  Are you threatening me for disputing neutralit...   \n",
       "54   001ffdcc3e7fb49c  Awesome! Then I'll simply disregard your notic...   \n",
       "57   00218d74784ce50b  \"\\n\\n GA Review II \\n\\nI'm sorry to say this, ...   \n",
       "58   0021fe88bc4da3e6  My Band Page's deletion. You thought I was gon...   \n",
       "63   002746baedcdff10  \"\\n\\n\"\"Christian arabs\"\"\\nHi. Could you please...   \n",
       "71   002a6beca33307b3  I would appreciate an apology from both of you...   \n",
       "74   002d6c9d9f85e81f  \"\\nWhile the magazine's masthead says \"\"TIME\"\"...   \n",
       "87   0036e50f42d0b679    Oh, it's me vandalising?xD See here. Greetings,   \n",
       "88   0037e59caead9dab  Website \\n\\nHey all,\\nI was thinking of gettin...   \n",
       "92   003910ffa2f50517  \"\\nAlmost got me too; I had to look it up to s...   \n",
       "99   003dbd1b9b354c1f  You can do all you're doing right now but if y...   \n",
       "102  0040017ef6277334  i can't believe no one has already put up this...   \n",
       "103  004176f28a17bf45  \"\\n\\nWell, after I asked you to provide the di...   \n",
       "106  00480b6e1f19601b  I tend to think that when the list is longer t...   \n",
       "107  0048de0c9422f64f  \"\\n\\n What's up with this? \\n\"\"If you are a re...   \n",
       "116  004d07d94cb92e35  Bigfoot Reference \\n\\nThe magazine is better k...   \n",
       "121  004f6dbe69f3545d  Conformity as healthy \\n\\nI may have missed it...   \n",
       "129  005306a4c109dab3  The statement drawn from Watchtower literature...   \n",
       "130  00537730daf8c5f1  Sorry about that.  I had checked, but had only...   \n",
       "134  00548f16a392d8ed  Meivazhi\\nI've had a go at restarting the Meiv...   \n",
       "149  005eb6d31a8d821e  From what I've seen with editors other than Er...   \n",
       "151  005f59485fcddeb0  \"\\n\\nSORRY PUCK BUT NO ONE EVER SAID DICK WAS ...   \n",
       "157  006120d209a4a46c  \"\\n\\n  \\n\\nYour request to be unblocked has be...   \n",
       "160  0063a8786a7034fc  \"== Attributing and classifying of personaliti...   \n",
       "167  006854d70298693e  Hi \\n\\nHi, good day.\\n\\nMy deepest apologies t...   \n",
       "175  006b888560bcdfcd                     \"know the sex of the foetus\"\"\"   \n",
       "179  006d11791d76b9f3  REPLY ABOVE:\\nThat was me, loser. The UN defin...   \n",
       "183  006f2c1459f3b6b1  \"== new ==\\n\\n{{userbox \\n TABTAB| id =  \\n TA...   \n",
       "188  0073059e6433db47  George W. Bush approval rating graph \\n\\nhttp:...   \n",
       "192  007571394afafcb5  \"\\n, editors don't care about your \"\"explanati...   \n",
       "193  007810bde7d6ebd4  About Mitch moved to Yggdrasill \\n\\nI have no ...   \n",
       "196  007bc29766a43e3c  Review Request \\n\\nHi,\\n\\nI'd like to request ...   \n",
       "199  007ecbb379c4a861  Al Messier \\nThis article was a non-notable bi...   \n",
       "\n",
       "     toxic  severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "1        0             0        0       0       0              0   \n",
       "14       0             0        0       0       0              0   \n",
       "20       0             0        0       0       0              0   \n",
       "21       0             0        0       0       0              0   \n",
       "37       0             0        0       0       0              0   \n",
       "48       0             0        0       0       0              0   \n",
       "50       0             0        0       0       0              0   \n",
       "52       0             0        0       0       0              0   \n",
       "54       0             0        0       0       0              0   \n",
       "57       0             0        0       0       0              0   \n",
       "58       1             0        1       0       0              0   \n",
       "63       0             0        0       0       0              0   \n",
       "71       0             0        0       0       0              0   \n",
       "74       0             0        0       0       0              0   \n",
       "87       0             0        0       0       0              0   \n",
       "88       0             0        0       0       0              0   \n",
       "92       0             0        0       0       0              0   \n",
       "99       0             0        0       0       0              0   \n",
       "102      0             0        0       0       0              0   \n",
       "103      0             0        0       0       0              0   \n",
       "106      0             0        0       0       0              0   \n",
       "107      0             0        0       0       0              0   \n",
       "116      0             0        0       0       0              0   \n",
       "121      0             0        0       0       0              0   \n",
       "129      0             0        0       0       0              0   \n",
       "130      0             0        0       0       0              0   \n",
       "134      0             0        0       0       0              0   \n",
       "149      0             0        0       0       0              0   \n",
       "151      1             0        0       0       0              0   \n",
       "157      0             0        0       0       0              0   \n",
       "160      0             0        0       0       0              0   \n",
       "167      0             0        0       0       0              0   \n",
       "175      0             0        0       0       0              0   \n",
       "179      0             0        0       0       1              0   \n",
       "183      0             0        0       0       0              0   \n",
       "188      0             0        0       0       0              0   \n",
       "192      0             0        0       0       0              0   \n",
       "193      0             0        0       0       0              0   \n",
       "196      0             0        0       0       0              0   \n",
       "199      0             0        0       0       0              0   \n",
       "\n",
       "                                    comment_text_clean  \\\n",
       "1    daww he matches this background colour im seem...   \n",
       "14   oh and the girl above started her arguments wi...   \n",
       "20   \\n\\n regarding your recent edits \\n\\nonce agai...   \n",
       "21   \\ngood to know about me yeah im studying nowde...   \n",
       "37   pretty much everyone from warren countysurroun...   \n",
       "48   \\nas for your claims of stalking that is absol...   \n",
       "50   \\n\\nbi you said you wanted to talk\\n\\nat the b...   \n",
       "52   are you threatening me for disputing neutralit...   \n",
       "54   awesome then ill simply disregard your notice ...   \n",
       "57   \\n\\n ga review ii \\n\\nim sorry to say this but...   \n",
       "58   my band pages deletion you thought i was gone ...   \n",
       "63   \\n\\nchristian arabs\\nhi could you please stop ...   \n",
       "71   i would appreciate an apology from both of you...   \n",
       "74   \\nwhile the magazines masthead says time the c...   \n",
       "87          oh its me vandalisingxd see here greetings   \n",
       "88   website \\n\\nhey all\\ni was thinking of getting...   \n",
       "92   \\nalmost got me too i had to look it up to see...   \n",
       "99   you can do all youre doing right now but if yo...   \n",
       "102  i cant believe no one has already put up this ...   \n",
       "103  \\n\\nwell after i asked you to provide the diff...   \n",
       "106  i tend to think that when the list is longer t...   \n",
       "107  \\n\\n whats up with this \\nif you are a religio...   \n",
       "116  bigfoot reference \\n\\nthe magazine is better k...   \n",
       "121  conformity as healthy \\n\\ni may have missed it...   \n",
       "129  the statement drawn from watchtower literature...   \n",
       "130  sorry about that  i had checked but had only c...   \n",
       "134  meivazhi\\nive had a go at restarting the meiva...   \n",
       "149  from what ive seen with editors other than eri...   \n",
       "151  \\n\\nsorry puck but no one ever said dick was n...   \n",
       "157  \\n\\n  \\n\\nyour request to be unblocked has bee...   \n",
       "160   attributing and classifying of personalities ...   \n",
       "167  hi \\n\\nhi good day\\n\\nmy deepest apologies tha...   \n",
       "175                         know the sex of the foetus   \n",
       "179  reply above\\nthat was me loser the un defines ...   \n",
       "183   new \\n\\nuserbox \\n tabtab id   \\n tabtab idc ...   \n",
       "188  george w bush approval rating graph \\n\\nhttpup...   \n",
       "192  \\n editors dont care about your explanations i...   \n",
       "193  about mitch moved to yggdrasill \\n\\ni have no ...   \n",
       "196  review request \\n\\nhi\\n\\nid like to request kl...   \n",
       "199  al messier \\nthis article was a nonnotable bio...   \n",
       "\n",
       "                                   comment_text_nostop  \\\n",
       "1    daww matches background colour im seemingly st...   \n",
       "14   oh girl started arguments stuck nose doesnt be...   \n",
       "20   regarding recent edits please read wpfilmplot ...   \n",
       "21                 good know yeah im studying nowdeepu   \n",
       "37   pretty much everyone warren countysurrounding ...   \n",
       "48   claims stalking absolute rubbish serves aggrav...   \n",
       "50   bi said wanted talk bottom lead section writte...   \n",
       "52   threatening disputing neutrality know country ...   \n",
       "54          awesome ill simply disregard notice thanks   \n",
       "57   ga review ii im sorry say fail articles gan se...   \n",
       "58   band pages deletion thought gone deleting comm...   \n",
       "63   christian arabs hi could please stop enforcing...   \n",
       "71   would appreciate apology see unlikely please d...   \n",
       "74   magazines masthead says time corporate name ti...   \n",
       "87                      oh vandalisingxd see greetings   \n",
       "88   website hey thinking getting website display p...   \n",
       "92                       almost got look see real talk   \n",
       "99   youre right get username youll able impact im ...   \n",
       "102  cant believe one already put page dilberts des...   \n",
       "103  well asked provide diffs within one hour next ...   \n",
       "106  tend think list longer rest article theres pro...   \n",
       "107  whats religiously politically motivated push i...   \n",
       "116  bigfoot reference magazine better known engine...   \n",
       "121  conformity healthy may missed article seem add...   \n",
       "129  statement drawn watchtower literature honestly...   \n",
       "130  sorry checked come dulas bay somehow missed du...   \n",
       "134  meivazhi ive go restarting meivazhi article st...   \n",
       "149  ive seen editors eric elephant room issue bait...   \n",
       "151  sorry puck one ever said dick number one clear...   \n",
       "157  request unblocked granted following reasons al...   \n",
       "160  attributing classifying personalities invitati...   \n",
       "167  hi hi good day deepest apologies made change m...   \n",
       "175                                    know sex foetus   \n",
       "179  reply loser un defines vietnam part southeast ...   \n",
       "183  new userbox tabtab id tabtab idc white tabtab ...   \n",
       "188  george w bush approval rating graph httpupload...   \n",
       "192  editors dont care explanations theyre accompan...   \n",
       "193                  mitch moved yggdrasill idea wasnt   \n",
       "196  review request hi id like request klm gaclass ...   \n",
       "199  al messier article nonnotable biography accord...   \n",
       "\n",
       "                                     comment_text_stem  \\\n",
       "1    daww match background colour im seem stuck tha...   \n",
       "14   oh girl start argument stuck nose doesnt belon...   \n",
       "20   regard recent edit pleas read wpfilmplot edit ...   \n",
       "21                    good know yeah im studi nowdeepu   \n",
       "37   pretti much everyon warren countysurround regi...   \n",
       "48   claim stalk absolut rubbish serv aggrav situat...   \n",
       "50   bi said want talk bottom lead section written ...   \n",
       "52   threaten disput neutral know countri quit comm...   \n",
       "54             awesom ill simpli disregard notic thank   \n",
       "57   ga review ii im sorri say fail articl gan seve...   \n",
       "58   band page delet thought gone delet comment pos...   \n",
       "63   christian arab hi could pleas stop enforc cate...   \n",
       "71   would appreci apolog see unlik pleas dont wast...   \n",
       "74   magazin masthead say time corpor name time inc...   \n",
       "87                          oh vandalisingxd see greet   \n",
       "88   websit hey think get websit display pictur che...   \n",
       "92                       almost got look see real talk   \n",
       "99   your right get usernam youll abl impact im say...   \n",
       "102  cant believ one alreadi put page dilbert deskt...   \n",
       "103  well ask provid diff within one hour next edit...   \n",
       "106  tend think list longer rest articl there probl...   \n",
       "107  what religi polit motiv push issu pleas refrai...   \n",
       "116  bigfoot refer magazin better known engin mine ...   \n",
       "121  conform healthi may miss articl seem address c...   \n",
       "129  statement drawn watchtow literatur honest clan...   \n",
       "130  sorri check come dula bay somehow miss dula di...   \n",
       "134  meivazhi ive go restart meivazhi articl style ...   \n",
       "149  ive seen editor eric eleph room issu baitingpo...   \n",
       "151  sorri puck one ever said dick number one clear...   \n",
       "157  request unblock grant follow reason allow user...   \n",
       "160  attribut classifi person invit input cultur li...   \n",
       "167  hi hi good day deepest apolog made chang made ...   \n",
       "175                                    know sex foetus   \n",
       "179  repli loser un defin vietnam part southeast as...   \n",
       "183  new userbox tabtab id tabtab idc white tabtab ...   \n",
       "188  georg w bush approv rate graph httpuploadwikim...   \n",
       "192  editor dont care explan theyr accompani reliab...   \n",
       "193                    mitch move yggdrasil idea wasnt   \n",
       "196  review request hi id like request klm gaclass ...   \n",
       "199  al messier articl nonnot biographi accord crit...   \n",
       "\n",
       "                                     comment_text_lemm  \n",
       "1    daww match background colour im seem stuck tha...  \n",
       "14   oh girl start argument stuck nose doesnt belon...  \n",
       "20   regard recent edit plea read wpfilmplot edit f...  \n",
       "21                    good know yeah im studi nowdeepu  \n",
       "37   pretti much everyon warren countysurround regi...  \n",
       "48   claim stalk absolut rubbish serv aggrav situat...  \n",
       "50   bi said want talk bottom lead section written ...  \n",
       "52   threaten disput neutral know countri quit comm...  \n",
       "54             awesom ill simpli disregard notic thank  \n",
       "57   ga review ii im sorri say fail articl gan seve...  \n",
       "58   band page delet thought gone delet comment pos...  \n",
       "63   christian arab hi could plea stop enforc categ...  \n",
       "71   would appreci apolog see unlik plea dont wast ...  \n",
       "74   magazin masthead say time corpor name time inc...  \n",
       "87                          oh vandalisingxd see greet  \n",
       "88   websit hey think get websit display pictur che...  \n",
       "92                       almost got look see real talk  \n",
       "99   your right get usernam youll abl impact im say...  \n",
       "102  cant believ one alreadi put page dilbert deskt...  \n",
       "103  well ask provid diff within one hour next edit...  \n",
       "106  tend think list longer rest articl there probl...  \n",
       "107  what religi polit motiv push issu plea refrain...  \n",
       "116  bigfoot refer magazin better known engin mine ...  \n",
       "121  conform healthi may miss articl seem address c...  \n",
       "129  statement drawn watchtow literatur honest clan...  \n",
       "130  sorri check come dula bay somehow miss dula di...  \n",
       "134  meivazhi ive go restart meivazhi articl style ...  \n",
       "149  ive seen editor eric eleph room issu baitingpo...  \n",
       "151  sorri puck one ever said dick number one clear...  \n",
       "157  request unblock grant follow reason allow user...  \n",
       "160  attribut classifi person invit input cultur li...  \n",
       "167  hi hi good day deepest apolog made chang made ...  \n",
       "175                                    know sex foetus  \n",
       "179  repli loser un defin vietnam part southeast as...  \n",
       "183  new userbox tabtab id tabtab idc white tabtab ...  \n",
       "188  georg w bush approv rate graph httpuploadwikim...  \n",
       "192  editor dont care explan theyr accompani reliab...  \n",
       "193                    mitch move yggdrasil idea wasnt  \n",
       "196  review request hi id like request klm gaclass ...  \n",
       "199  al messier articl nonnot biographi accord crit...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 0\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "import plotly.graph_objs as go\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.models import Circle, MultiLine, Range1d, LabelSet\n",
    "from bokeh.plotting import figure, from_networkx, show\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh.palettes import Blues8\n",
    "from bokeh.models.graphs import NodesAndLinkedEdges\n",
    "from bokeh.io import save\n",
    "\n",
    "# Loading the dataframe containing the comments and attribute labels\n",
    "df = pd.read_excel(\"preprocessed_train.xlsx\")\n",
    "#df = df.head(200) # part for code testing\n",
    "df[\"comment_text_lemm\"] = df[\"comment_text_lemm\"].astype(str)\n",
    "\n",
    "# Splitting the dataset into training and testing sets\n",
    "train_df = df.sample(frac=0.8, random_state=42)\n",
    "test_df = df.drop(train_df.index)\n",
    "display(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6777f",
   "metadata": {},
   "source": [
    "## Tokenizing and labeling of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef68a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Loading the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "labels = df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values\n",
    "labels = torch.tensor(labels, dtype=torch.float32)\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "train_labels, test_labels = train_test_split(labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Tokenizing the comment text using the BERT tokenizer\n",
    "train_encodings = tokenizer(train_df[\"comment_text_lemm\"].tolist(), truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_df[\"comment_text_lemm\"].tolist(), truncation=True, padding=True)\n",
    "\n",
    "# Encoding the tokenized sequences using the BERT encoding scheme to obtain input features\n",
    "train_input_ids = torch.tensor(train_encodings[\"input_ids\"])\n",
    "train_attention_mask = torch.tensor(train_encodings[\"attention_mask\"])\n",
    "test_input_ids = torch.tensor(test_encodings[\"input_ids\"])\n",
    "test_attention_mask = torch.tensor(test_encodings[\"attention_mask\"])\n",
    "\n",
    "# Making a TensorDataset for training and testing sets\n",
    "train_dataset = TensorDataset(train_input_ids, train_attention_mask, train_labels)\n",
    "test_dataset = TensorDataset(test_input_ids, test_attention_mask, test_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9475233e",
   "metadata": {},
   "source": [
    "## Building BERT model and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa63ee46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Building a BERT-based NLP attention model with two layers ver2\n",
    "class ToxicityClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super(ToxicityClassifier, self).__init__()\n",
    "        self.bert = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        return logits\n",
    "\n",
    "num_labels = 6  # Number of toxic attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de127770",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: Average Loss = 0.4071\n"
     ]
    }
   ],
   "source": [
    "# 3 DataLoader for training and testing sets\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Making an instance of the ToxicityClassifier model\n",
    "model = ToxicityClassifier(num_labels)\n",
    "\n",
    "# Defining the optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "for epoch in range(5):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids, attention_mask, labels = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids, attention_mask, labels = batch\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            logits = model(input_ids, attention_mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f\"Epoch {epoch+1}/{5}: Average Loss = {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a1aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4 Evaluating the model\n",
    "model.eval()\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids, attention_mask, _ = batch\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        logits = torch.sigmoid(logits)\n",
    "        predictions.extend(logits.cpu().numpy())\n",
    "\n",
    "predictions = torch.tensor(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e2efc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 Converting predictions to binary values (0 or 1) based on a threshold\n",
    "threshold = 0.5\n",
    "binary_predictions = (predictions >= threshold).to(torch.float32)\n",
    "\n",
    "# Convert labels to numpy.ndarray if they are torch.Tensor\n",
    "if isinstance(labels, torch.Tensor):\n",
    "    labels = labels.cpu().numpy()\n",
    "\n",
    "# Ensure that predictions and labels have the same number of samples\n",
    "if len(binary_predictions) != len(labels):\n",
    "    raise ValueError(\"Number of samples in predictions and labels does not match.\")\n",
    "\n",
    "# Check if there are any positive samples in the labels\n",
    "if np.sum(labels) == 0:\n",
    "    print(\"No positive samples in the labels.\")\n",
    "else:\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(labels, binary_predictions)\n",
    "    precision = precision_score(labels, binary_predictions, average=\"micro\", zero_division=1)\n",
    "    recall = recall_score(labels, binary_predictions, average=\"micro\", zero_division=1)\n",
    "    f1 = f1_score(labels, binary_predictions, average=\"micro\", zero_division=1)\n",
    "\n",
    "    # Print the evaluation metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfff85",
   "metadata": {},
   "source": [
    "## Finding toxic words for network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83d20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 Fixing data for futher analysis\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "train = df\n",
    "train['comment_text'] = train['comment_text'].astype(str)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871bdd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7 Reindexing\n",
    "train.index = train['id']\n",
    "x_train = train['comment_text']\n",
    "y_train = train.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead99d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 If some kind of toxicity is detected, the sum across rows will yield one, \n",
    "# and the subtraction will give zero, and one otherwise\n",
    "y_train['clean'] = 1 - y_train.sum(axis=1) >= 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f5a7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 The sum operation yield a series, and a series behaves like a dictionary\n",
    "# as it has the items function that returns index-value tuples.\n",
    "kinds, counts = zip(*y_train.sum(axis=0).items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5044459",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 7.3\n",
    "bars = go.Bar(\n",
    "        y=counts,\n",
    "        x=kinds,\n",
    "    )\n",
    "\n",
    "layout = go.Layout(\n",
    "    title=\"Class distribution in train set\"\n",
    ")\n",
    "\n",
    "fig = go.Figure(data=[bars], layout=layout)\n",
    "iplot(fig, filename='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5a2444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'tagger', 'ner'])\n",
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678a516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.1 Additional normalization of data\n",
    "def normalize(comment, lowercase, remove_stopwords):\n",
    "    if lowercase:\n",
    "        comment = comment.lower()\n",
    "    comment = nlp(comment)\n",
    "    lemmatized = list()\n",
    "    for word in comment:\n",
    "        lemma = word.lemma_.strip()\n",
    "        if lemma:\n",
    "            if not remove_stopwords or (remove_stopwords and lemma not in stops):\n",
    "                lemmatized.append(lemma)\n",
    "    return \" \".join(lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c630f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.2\n",
    "x_train_lemmatized = x_train.apply(normalize, lowercase=True, remove_stopwords=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337f164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8.3 Demo\n",
    "x_train_lemmatized.sample(1).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33e71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9 Counting toxic words, that are met most often in comments\n",
    "from collections import Counter\n",
    "word_counts = dict()\n",
    "\n",
    "for kind in y_train.columns:\n",
    "    word_counts[kind] = Counter()\n",
    "    comments = x_train_lemmatized[y_train[kind]==1]\n",
    "    for _, comment in comments.iteritems():\n",
    "        word_counts[kind].update(comment.split(\" \"))\n",
    "def most_common_words(kind, num_words=15):\n",
    "    words, counts = zip(*word_counts[kind].most_common(num_words)[::-1])\n",
    "    bars = go.Bar(\n",
    "        y=words,\n",
    "        x=counts,\n",
    "        orientation=\"h\"\n",
    "    )\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title=\"Most common words of the class \\\"{}\\\"\".format(kind),\n",
    "        yaxis=dict(\n",
    "            ticklen=8  # to add some space between yaxis labels and the plot\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig = go.Figure(data=[bars], layout=layout)\n",
    "    iplot(fig, filename='bar')\n",
    "most_common_words(\"toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2beac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Plot for every type of comments, showing words\n",
    "most_common_words(\"severe_toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4b994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.2\n",
    "most_common_words(\"threat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449da763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.3\n",
    "most_common_words(\"clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d99d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 Converting the 'comment_text' column to string\n",
    "df['comment_text_lemm'] = df['comment_text_lemm'].astype(str)\n",
    "\n",
    "# Concatenating all the toxic comments into a single string\n",
    "all_toxic_comments = ' '.join(df[df['toxic'] == 1]['comment_text_lemm'])\n",
    "\n",
    "# Splitting the string into individual words\n",
    "all_toxic_words = all_toxic_comments.split()\n",
    "\n",
    "# Calculation of the frequency of each word\n",
    "word_frequency = pd.Series(all_toxic_words).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50386618",
   "metadata": {},
   "source": [
    "## Network visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bf730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 Getting the word embeddings for toxic words\n",
    "toxic_words = all_toxic_words\n",
    "\n",
    "# Loading the BERT model and tokenizer\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)\n",
    "\n",
    "# Tokenizing the toxic words\n",
    "tokenized_words = tokenizer(toxic_words, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Forwarding pass to obtain word embeddings\n",
    "with torch.no_grad():\n",
    "    outputs = model(**tokenized_words)\n",
    "    word_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "\n",
    "# Reshaping the word embeddings to remove the batch dimension\n",
    "word_embeddings = word_embeddings.reshape(word_embeddings.size(0), -1)\n",
    "\n",
    "# Calculating similarity scores between word embeddings\n",
    "similarity_scores = cosine_similarity(word_embeddings.cpu().numpy())\n",
    "\n",
    "# Creating a graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# Adding nodes to the graph with word signatures\n",
    "for i, word in enumerate(toxic_words):\n",
    "    signature = tokenizer.convert_ids_to_tokens(tokenized_words['input_ids'][i].tolist())\n",
    "    G.add_node(word, signature=signature)\n",
    "\n",
    "# Adding edges to the graph\n",
    "for i, word1 in enumerate(toxic_words):\n",
    "    for j, word2 in enumerate(toxic_words):\n",
    "        if i != j:\n",
    "            similarity = similarity_scores[i, j]\n",
    "            G.add_edge(word1, word2, weight=similarity)\n",
    "\n",
    "# Drawing the graph\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "weights = [data['weight'] for _, _, data in G.edges(data=True)]\n",
    "edges = nx.draw_networkx_edges(G, pos, edge_color=weights, edge_cmap=plt.cm.Reds, width=2)\n",
    "nodes = nx.draw_networkx_nodes(G, pos, node_color='blue', alpha=0.7)\n",
    "\n",
    "# Adding word signatures to the node labels\n",
    "node_labels = {node: ' '.join(G.nodes[node]['signature']) for node in G.nodes}\n",
    "nx.draw_networkx_labels(G, pos, labels=node_labels, font_size=6)\n",
    "\n",
    "# Adding colorbar for edge weights\n",
    "cbar = plt.colorbar(edges)\n",
    "cbar.set_label('Connection Strength')\n",
    "\n",
    "plt.title('Toxic Words Network')\n",
    "plt.figure(figsize=(12, 8)) \n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a80a59",
   "metadata": {},
   "source": [
    "First version of network is not well-representing data. So all the additional info will be controlled by making interactive plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from bokeh.models import Circle, MultiLine, Range1d\n",
    "from bokeh.plotting import figure, from_networkx, show\n",
    "from bokeh.models.sources import ColumnDataSource\n",
    "from bokeh.models import LabelSet\n",
    "from bokeh.palettes import Blues8\n",
    "from bokeh.models.graphs import NodesAndLinkedEdges\n",
    "from bokeh.io import save\n",
    "import networkx as nx\n",
    "\n",
    "# 12 Choosing colors for node and edge highlighting\n",
    "node_highlight_color = 'white'\n",
    "edge_highlight_color = 'black'\n",
    "\n",
    "# Choosing attributes from G network to size and color by â€” setting manual size (e.g. 10) or color (e.g. 'skyblue') also allowed\n",
    "size_by_this_attribute = 'adjusted_node_size'\n",
    "color_by_this_attribute = 'modularity_color'\n",
    "\n",
    "# Picking a color palette\n",
    "color_palette = Blues8\n",
    "\n",
    "title = 'Toxic Words Network'\n",
    "\n",
    "# Establishing which categories will appear when hovering over each node\n",
    "HOVER_TOOLTIPS = [\n",
    "    (\"Word:\", \"@signature\"),\n",
    "    #(\"Centrality Degree:\", \"@degree\"),\n",
    "]\n",
    "\n",
    "# Creating a plot â€” seting dimensions, toolbar, and title\n",
    "plot = figure(tooltips=HOVER_TOOLTIPS,\n",
    "              tools=\"pan,wheel_zoom,save,reset\", active_scroll='wheel_zoom',\n",
    "              plot_width=1080, plot_height=900,  # Adjust the plot width and height\n",
    "              x_range=Range1d(-1.1, 1.1), y_range=Range1d(-1.1, 1.1), title=title)\n",
    "\n",
    "# Applying force-directed layout (spring layout) to the graph\n",
    "pos = nx.spring_layout(G)\n",
    "\n",
    "# Calculating node degrees\n",
    "node_degrees = dict(G.degree())\n",
    "\n",
    "# Setting node attributes\n",
    "network_graph = from_networkx(G, pos, scale=2, center=(0, 0))\n",
    "network_graph.node_renderer.glyph = Circle(size=15, fill_color=\"#87C38F\", fill_alpha=0.7)\n",
    "network_graph.node_renderer.selection_glyph = Circle(size=15, fill_color=\"#17BEBB\", fill_alpha=0.7)\n",
    "network_graph.node_renderer.hover_glyph = Circle(size=15, fill_color=\"#C44536\", fill_alpha=0.7)\n",
    "\n",
    "# Setting edge attributes\n",
    "network_graph.edge_renderer.glyph = MultiLine(line_color=\"black\", line_width=1.5)\n",
    "network_graph.edge_renderer.selection_glyph = MultiLine(line_color=\"black\", line_width=1.5)\n",
    "network_graph.edge_renderer.hover_glyph = MultiLine(line_color=\"#C44536\", line_width=2.5)\n",
    "\n",
    "# Enabling highlighting of connected nodes and edges\n",
    "network_graph.selection_policy = NodesAndLinkedEdges()\n",
    "network_graph.inspection_policy = NodesAndLinkedEdges()\n",
    "\n",
    "# Adding the graph to the plot\n",
    "plot.renderers.append(network_graph)\n",
    "\n",
    "# Creating a BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Adding word signatures and centrality degrees as labels\n",
    "node_labels = {}\n",
    "for node in G.nodes:\n",
    "    signature = G.nodes[node]['signature']\n",
    "    degree = node_degrees[node]\n",
    "    if len(signature) > 1:\n",
    "        node_name = tokenizer.tokenize(node)\n",
    "        node_name = [token for token in node_name if not tokenizer.convert_tokens_to_string([token]) in tokenizer.all_special_tokens]\n",
    "        node_labels[node] = f\"{node_name[1:-1]}\\nDegree: {degree}\"\n",
    "    else:\n",
    "        node_labels[node] = f\"Degree: {degree}\"\n",
    "\n",
    "x = [pos[node][0] for node in G.nodes]\n",
    "y = [pos[node][1] for node in G.nodes]\n",
    "\n",
    "source = ColumnDataSource({'x': x, 'y': y, 'word': list(node_labels.values()), 'signature': list(node_labels.values()), 'degree': list(node_degrees.values())})\n",
    "labels = LabelSet(x='x', y='y', text='word', text_font_size='6pt', source=source, render_mode='canvas')\n",
    "\n",
    "# Showing the plot\n",
    "plot.add_layout(labels)\n",
    "show(plot)\n",
    "save(plot, filename=f\"{title}-1.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52977329",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
