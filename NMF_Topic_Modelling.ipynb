{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123bc5df",
   "metadata": {},
   "source": [
    "## Topic Modeling NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee3d35",
   "metadata": {},
   "source": [
    "NMF\n",
    "NonNegative Matrix Factorization (NMF) is an unsupervised technique, so there is no labeling of the topics by which the model will be trained. The way this works is that NMF decomposes (or factorizes) vectors of large dimension to a representation of smaller dimension. These vectors of smaller dimension are non-negative, which also means that their coefficients are non-negative.\n",
    "\n",
    "Using the original matrix (A), NMF will give you two matrices (W and H). W are the topics found, and His are the coefficients (weights) for these topics. In other words, A is comments on words (the original), his comments on topics and topics on words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746ed578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "merged_df = pd.read_excel(\"preprocessed_train.xlsx\")\n",
    "merged_df[\"comment_text_lemm\"] = merged_df[\"comment_text_lemm\"].astype(str)\n",
    "clmn = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# Check if all columns of interest contain 0 and create a boolean mask\n",
    "mask = (merged_df[clmn] == 0).all(axis=1)\n",
    "\n",
    "# Filter the DataFrame to keep rows where the mask is False\n",
    "filtered_df = merged_df[~mask]\n",
    "#merged_df = filtered_df.head(5000) # part for testing\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59421717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Fitting tf-idf model\n",
    "X = vectorizer.fit_transform(merged_df['comment_text_lemm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d3c6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['comment_text_lemm'] = merged_df['comment_text_lemm'].astype(str)\n",
    "# Convert text to lowercase\n",
    "merged_df['cleaned_text'] = merged_df['comment_text_lemm'].str.lower()\n",
    "\n",
    "# Tokenize the text into words\n",
    "merged_df['tokens'] = merged_df['cleaned_text'].apply(lambda x: word_tokenize(x))\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737eb4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim import corpora, models\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create a corpus from a list of texts\n",
    "texts = merged_df['tokens'].values\n",
    "dictionary = corpora.Dictionary(texts, prune_at=2000)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cda415f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from gensim.models.nmf import Nmf\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "coh_list = []\n",
    "for n_topics in range(3,50+1):\n",
    "    # Train the model on the corpus\n",
    "    nmf = Nmf(corpus, num_topics=n_topics, id2word=dictionary, random_state=42)\n",
    "    # Estimate coherence\n",
    "    cm = CoherenceModel(model=nmf, texts=texts, dictionary=dictionary, coherence='u_mass')\n",
    "    coherence = cm.get_coherence_per_topic() # get coherence value\n",
    "    coh_list.append(coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7d91b7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.decomposition import NMF\n",
    "\n",
    "tfidf = X\n",
    "\n",
    "n_topics=7\n",
    "n_top_words = 10\n",
    "\n",
    "nmf = NMF(n_components=n_topics, random_state=42, l1_ratio=.5).fit(tfidf)\n",
    "nmf_embedding = nmf.transform(tfidf)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(\"Topics found via NMF:\")\n",
    "for topic_idx, topic in enumerate(nmf.components_):\n",
    "    print(\"\\nTopic {}:\".format(topic_idx))\n",
    "    print(\" \".join(['[{}]'.format(feature_names[i]) for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a44d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = ['Mental Abilities and Origin',\n",
    "          'Complaints and Requests for Blocking',\n",
    "          'References to Anatomy',\n",
    "          'Homophobia',\n",
    "          'Calls for Suicide',\n",
    "          'Belittling',\n",
    "          'Hatred']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db52b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bokeh.io import output_notebook\n",
    "from bokeh.plotting import figure, show\n",
    "from bokeh.models import HoverTool, CustomJS, ColumnDataSource, Slider, Range1d\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import all_palettes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8124e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "\n",
    "umap_embr = umap.UMAP(n_neighbors=10, metric='cosine', min_dist=0.1, random_state=42)\n",
    "embedding = umap_embr.fit_transform(np.asarray(tfidf.todense()))\n",
    "embedding = pd.DataFrame(embedding, columns=['x', 'y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f9caab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "centroids = umap_embr.transform(nmf.components_)\n",
    "embedding['hue'] = nmf_embedding.argmax(axis=1)\n",
    "my_colors = [all_palettes['Category20'][20][i] for i in embedding.hue]\n",
    "\n",
    "legend_list = []\n",
    "for color in all_palettes['Category20'][20][:n_topics]:   \n",
    "    legend_list.append(mpatches.Ellipse((0, 0), 1, 1, fc=color))\n",
    "    \n",
    "fig,ax = plt.subplots(figsize=(12,13))\n",
    "ax.scatter(embedding.x, embedding.y, c=my_colors, alpha=0.8)\n",
    "ax.scatter(centroids[:,0], centroids[:,1], c='black', s=100, alpha=1, marker='x')\n",
    "fig.legend(legend_list, topics, loc=(0.18,0.89), ncol=3)\n",
    "plt.subplots_adjust(top=0.82);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965955a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
