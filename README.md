# Research Proposal: Predicting Toxicity in Online Comments using NLP

## 1. Title

Predicting Toxicity in Online Comments using NLP

## 2. Abstract

Online communication has revolutionized how people interact with one another, but it has also created new challenges in managing toxic language in online comments. In this project, we propose to develop a natural language processing (NLP) model to detect toxic language in online comments. We will use a dataset from the Jigsaw Unintended Bias in Toxicity Classification competition to train and evaluate our model. Our approach will include a lexical coherence graph modeling technique using word embeddings, as well as a stacking-based efficient method for toxic language detection. We expect to achieve high accuracy in detecting toxic language in online comments, which will be useful for content moderators and online community managers.

## 3. Introduction

The rise of social media and other online platforms has made it easier than ever for people to express their opinions and engage in discussions with others around the world. However, with the increased freedom of online communication comes the challenge of managing toxic language in online comments. Toxic comments can be defined as those that contain offensive, threatening, or harassing language, which can be harmful to the person who receives the comment or to the community as a whole. Content moderators and online community managers are responsible for monitoring and removing toxic comments, but this is a challenging task given the vast amounts of online content that are generated every day.

Natural language processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans using natural language. NLP has been used for a variety of applications, including sentiment analysis, language translation, and speech recognition. In recent years, NLP has also been used to detect toxic language in online comments. In this project, we propose to develop an NLP model to detect toxic language in online comments, which will be useful for content moderators and online community managers.

## 4. Main Part

### Literature Review

Previous research has shown that NLP can be an effective tool for detecting toxic language in online comments. Mesgar and Strube (2016) proposed a lexical coherence graph modeling technique using word embeddings, which they used to detect coherence violations in online comments. Oikawa, Nakayama, and Murakami (2022) proposed a stacking-based efficient method for toxic language detection on live streaming chat. Rossi et al. (2020) proposed a temporal graph network approach for deep learning on dynamic graphs, which they used to predict temporal patterns in online social networks.

### Anticipated NLP Methods

In this project, we will use a combination of the lexical coherence graph modeling technique proposed by Mesgar and Strube (2016) and the stacking-based efficient method proposed by Oikawa, Nakayama, and Murakami (2022) to develop our NLP model. We will use the Jigsaw Unintended Bias in Toxicity Classification dataset, which contains a large number of comments labeled as toxic or non-toxic, to train and evaluate our model. We will also use word embeddings to represent the meaning of words in the comments and to create the coherence graph.

### Expected Results

We expect to achieve high accuracy in detecting toxic language in online comments using our NLP model. This will be useful for content moderators and online community managers, who can use the model to automatically flag toxic comments for removal. We also expect that our model will be able to detect patterns in the language used in toxic comments, which can be useful for understanding the nature of toxic language in online communication.

## 5. Conclusion

In this project, we propose to develop an NLP model to detect toxic language in online comments using a combination of the lexical coherence graph modeling technique and the stacking

## Data
https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/data
